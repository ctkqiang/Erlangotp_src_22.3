/*
 *  Warning: Do not edit this file.
 *  Auto-generated by 'beam_makeops'.
 */

OpCase(bs_add_jsstx):
{
  Eterm tmp_packed2 = I[3];
  Eterm targ1;
  Eterm targ2;
  GetSource(I[1], targ1);
  GetSource(I[2], targ2);
  {
    Eterm Op1 = targ1;
    Eterm Op2 = targ2;
    Uint unit = tb(tmp_packed2&BEAM_LOOSE_MASK);

    if (is_both_small(Op1, Op2)) {
      Sint Arg1 = signed_val(Op1);
      Sint Arg2 = signed_val(Op2);

      if (Arg1 >= 0 && Arg2 >= 0) {
        do {
          Uint a = Arg2;
          Uint b = unit;
          Uint res;
#ifdef HAVE_OVERFLOW_CHECK_BUILTINS
          if (__builtin_mul_overflow(a, b, &res)) {
            c_p->freason = SYSTEM_LIMIT;

            /*
            * In a correctly working program, we expect failures in
            * guards to be more likely than failures in bodies.
            */

            if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
              ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
              I += jb(BeamExtraData(I[0])) + 0;;
              Goto(*I);;
            }
            goto find_func_info;;;
          }
#else
          res = a * b;
          if (res / b != a) {
            c_p->freason = SYSTEM_LIMIT;

            /*
            * In a correctly working program, we expect failures in
            * guards to be more likely than failures in bodies.
            */

            if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
              ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
              I += jb(BeamExtraData(I[0])) + 0;;
              Goto(*I);;
            }
            goto find_func_info;;;
          }
#endif
          Op1 = res;
        } while (0);
        Op1 += Arg1;

        store_bs_add_result:
        if (Op1 <= MAX_SMALL) {
          Op1 = make_small(Op1);
        } else {
          /*
          * May generate a heap fragment, but in this
          * particular case it is OK, since the value will be
          * stored into an x register (the GC will scan x
          * registers for references to heap fragments) and
          * there is no risk that value can be stored into a
          * location that is not scanned for heap-fragment
          * references (such as the heap).
          */
          SWAPOUT;
          Op1 = erts_make_integer(Op1, c_p);
          HTOP = HEAP_TOP(c_p);
        }
        xb((tmp_packed2>>BEAM_LOOSE_SHIFT)) = Op1;
        SET_I((BeamInstr *) I+4);
        Goto(*I);;
      }
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    } else {
      Uint a;
      Uint b;
      Uint c;

      /*
      * Now we know that one of the arguments is
      * not a small. We must convert both arguments
      * to Uints and check for errors at the same time.
      *
      * Error checking is tricky.
      *
      * If one of the arguments is not numeric or
      * not positive, the error reason is BADARG.
      *
      * Otherwise if both arguments are numeric,
      * but at least one argument does not fit in
      * an Uint, the reason is SYSTEM_LIMIT.
      */

      if (!term_to_Uint(Op1, &a)) {
        if (a == BADARG) {
          c_p->freason = BADARG;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
            ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
            I += jb(BeamExtraData(I[0])) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
        if (!term_to_Uint(Op2, &b)) {
          c_p->freason = b;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
            ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
            I += jb(BeamExtraData(I[0])) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;
        }
        c_p->freason = SYSTEM_LIMIT;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
          ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
          I += jb(BeamExtraData(I[0])) + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      } else if (!term_to_Uint(Op2, &b)) {
        c_p->freason = b;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
          ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
          I += jb(BeamExtraData(I[0])) + 0;;
          Goto(*I);;
        }
        goto find_func_info;;
      }

      /*
      * The arguments are now correct and stored in a and b.
      */

      do {
        Uint a = b;
        Uint b = unit;
        Uint res;
#ifdef HAVE_OVERFLOW_CHECK_BUILTINS
        if (__builtin_mul_overflow(a, b, &res)) {
          c_p->freason = SYSTEM_LIMIT;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
            ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
            I += jb(BeamExtraData(I[0])) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
#else
        res = a * b;
        if (res / b != a) {
          c_p->freason = SYSTEM_LIMIT;

          /*
          * In a correctly working program, we expect failures in
          * guards to be more likely than failures in bodies.
          */

          if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
            ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
            I += jb(BeamExtraData(I[0])) + 0;;
            Goto(*I);;
          }
          goto find_func_info;;;
        }
#endif
        c = res;
      } while (0);
      Op1 = a + c;
      if (Op1 < a) {
        /*
        * If the result is less than one of the
        * arguments, there must have been an overflow.
        */
        c_p->freason = SYSTEM_LIMIT;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
          ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
          I += jb(BeamExtraData(I[0])) + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      goto store_bs_add_result;
    }
    /* No fallthrough */
    ASSERT(0);
  }
}

{
  Eterm context;
  OpCase(bs_get_tail_xdt):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto bs_get_tail__execute;

  OpCase(bs_get_tail_ydt):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto bs_get_tail__execute;

  bs_get_tail__execute:
  {
    Eterm tmp_packed1 = I[1];
    Eterm dst = db(tmp_packed1&BEAM_LOOSE_MASK);
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    BeamInstr next_pf = BeamCodeAddr(I[2]);
    ErlBinMatchBuffer* mb;
    Uint size, offs;
    ErlSubBin* sb;

    ASSERT(header_is_bin_matchstate(*boxed_val(context)));

    do {
      Uint need = ERL_SUB_BIN_SIZE;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        do {
          //
          // Since a garbage collection is expensive anyway, we can afford
          // to save the instruction counter so that the correct function will
          // be pointed in the crash dump if the garbage collection fails
          // because of insufficient memory.
          //
          SWAPOUT;
          c_p->i = I;
        } while (0);
        reg[tb((tmp_packed1>>BEAM_LOOSE_SHIFT))] = context;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb((tmp_packed1>>BEAM_LOOSE_SHIFT))+1, FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        context = reg[tb((tmp_packed1>>BEAM_LOOSE_SHIFT))];
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(ERL_SUB_BIN_SIZE);
    } while (0);

    mb = ms_matchbuffer(context);

    offs = mb->offset;
    size = mb->size - offs;

    sb = (ErlSubBin *) HTOP;
    HTOP += ERL_SUB_BIN_SIZE;

    sb->thing_word = HEADER_SUB_BIN;
    sb->size = BYTE_OFFSET(size);
    sb->bitsize = BIT_OFFSET(size);
    sb->offs = BYTE_OFFSET(offs);
    sb->bitoffs = BIT_OFFSET(offs);
    sb->is_writable = 0;
    sb->orig = mb->orig;

    dst_ptr = REG_TARGET_PTR(dst);
    *dst_ptr = make_binary(sb);
    I += 2;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }

}

OpCase(bs_init_writable):
{
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  HEAVY_SWAPOUT;
  r(0) = erts_bs_init_writable(c_p, r(0));
  HEAVY_SWAPIN;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(bs_put_string_WW):
{
  BeamInstr next_pf = BeamCodeAddr(I[3]);
  erts_new_bs_put_string(ERL_BITS_ARGS_2((byte *) I[2], I[1]));
  I += 3;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(bs_put_utf16_jtS):
{
  Eterm tmp_packed2 = I[1];
  if (!erts_bs_put_utf16(ERL_BITS_ARGS_2(Sb((tmp_packed2>>BEAM_LOOSE_SHIFT)), tb(tmp_packed2&BEAM_LOOSE_MASK)))) {
    c_p->freason = BADARG;

    /*
    * In a correctly working program, we expect failures in
    * guards to be more likely than failures in bodies.
    */

    if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
      ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
      I += jb(BeamExtraData(I[0])) + 0;;
      Goto(*I);;
    }
    goto find_func_info;;;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_set_position_xx):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchBuffer* mb;
  Eterm context;

  context = xb(tmp_packed1&BEAM_TIGHT_MASK);
  ASSERT(header_is_bin_matchstate(*boxed_val(context)));

  mb = ms_matchbuffer(context);
  mb->offset = unsigned_val(xb((tmp_packed1>>BEAM_TIGHT_SHIFT)));
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(bs_set_position_xy):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchBuffer* mb;
  Eterm context;

  context = xb(tmp_packed1&BEAM_TIGHT_MASK);
  ASSERT(header_is_bin_matchstate(*boxed_val(context)));

  mb = ms_matchbuffer(context);
  mb->offset = unsigned_val(yb((tmp_packed1>>BEAM_TIGHT_SHIFT)));
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(bs_set_position_yx):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchBuffer* mb;
  Eterm context;

  context = yb(tmp_packed1&BEAM_TIGHT_MASK);
  ASSERT(header_is_bin_matchstate(*boxed_val(context)));

  mb = ms_matchbuffer(context);
  mb->offset = unsigned_val(xb((tmp_packed1>>BEAM_TIGHT_SHIFT)));
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(bs_set_position_yy):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchBuffer* mb;
  Eterm context;

  context = yb(tmp_packed1&BEAM_TIGHT_MASK);
  ASSERT(header_is_bin_matchstate(*boxed_val(context)));

  mb = ms_matchbuffer(context);
  mb->offset = unsigned_val(yb((tmp_packed1>>BEAM_TIGHT_SHIFT)));
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(bs_test_tail_imm2_fxW):
{
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(xb(I[1]));
  if (_mb->size - _mb->offset != I[2]) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_tail_imm2_fyW):
{
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(yb(I[1]));
  if (_mb->size - _mb->offset != I[2]) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_unit8_fx):
{
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(xb(I[1]));
  if ((_mb->size - _mb->offset) & 7) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_unit8_fy):
{
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(yb(I[1]));
  if ((_mb->size - _mb->offset) & 7) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_unit_fxt):
{
  Eterm tmp_packed2 = I[1];
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(xb(tmp_packed2&BEAM_LOOSE_MASK));
  if ((_mb->size - _mb->offset) % tb((tmp_packed2>>BEAM_LOOSE_SHIFT))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_unit_fyt):
{
  Eterm tmp_packed2 = I[1];
  ErlBinMatchBuffer *_mb;
  _mb = ms_matchbuffer(yb(tmp_packed2&BEAM_LOOSE_MASK));
  if ((_mb->size - _mb->offset) % tb((tmp_packed2>>BEAM_LOOSE_SHIFT))) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_zero_tail2_fx):
{
  ErlBinMatchBuffer *_mb;
  _mb = (ErlBinMatchBuffer*) ms_matchbuffer(xb(I[1]));
  if (_mb->size != _mb->offset) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(bs_test_zero_tail2_fy):
{
  ErlBinMatchBuffer *_mb;
  _mb = (ErlBinMatchBuffer*) ms_matchbuffer(yb(I[1]));
  if (_mb->size != _mb->offset) {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(fconv_Sl):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  Eterm src = Sb(tmp_packed1&BEAM_TIGHT_MASK);

  if (is_small(src)) {
    lb((tmp_packed1>>BEAM_TIGHT_SHIFT)) = (double) signed_val(src);
  } else if (is_big(src)) {
    if (big_to_double(src, &lb((tmp_packed1>>BEAM_TIGHT_SHIFT))) < 0) {
      c_p->freason = BADARITH;
      goto find_func_info;;
    }
  } else if (is_float(src)) {
    do {
      GET_DOUBLE(src, *(FloatDef *) &lb((tmp_packed1>>BEAM_TIGHT_SHIFT)));
    } while (0);
  } else {
    c_p->freason = BADARITH;
    goto find_func_info;;
  }
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(fload_Sl):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  do {
    GET_DOUBLE(Sb(tmp_packed1&BEAM_TIGHT_MASK), *(FloatDef *) &lb((tmp_packed1>>BEAM_TIGHT_SHIFT)));
  } while (0);
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(fload_ql):
{
  BeamInstr next_pf = BeamCodeAddr(I[2]);
  do {
    GET_DOUBLE(I[1], *(FloatDef *) &lb(BeamExtraData(I[0])));
  } while (0);
  I += 2;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(fstore_ld):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  Eterm dst = db((tmp_packed1>>BEAM_TIGHT_SHIFT));
  Eterm* dst_ptr = REG_TARGET_PTR(dst);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  PUT_DOUBLE(*((FloatDef *) &lb(tmp_packed1&BEAM_TIGHT_MASK)), HTOP);
  *dst_ptr = make_float(HTOP);
  HTOP += FLOAT_SIZE_OBJECT;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_append_jIttsx):
{
  Eterm tmp_packed2 = I[1];
  Eterm tmp_packed3 = I[2];
  Eterm targ1;
  GetSource(I[3], targ1);
  {
    Uint live = tb((tmp_packed2>>BEAM_WIDE_SHIFT));
    Uint res;

    HEAVY_SWAPOUT;
    reg[live] = x(SCRATCH_X_REG);
    res = erts_bs_append(c_p, reg, live, targ1, Ib(tmp_packed2&BEAM_WIDE_MASK), tb(tmp_packed3&BEAM_LOOSE_MASK));
    HEAVY_SWAPIN;
    if (is_non_value(res)) {
      /* c_p->freason is already set (to BADARG or SYSTEM_LIMIT). */

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;
    }
    xb((tmp_packed3>>BEAM_LOOSE_SHIFT)) = res;
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_bs_append_jIttsy):
{
  Eterm tmp_packed2 = I[1];
  Eterm tmp_packed3 = I[2];
  Eterm targ1;
  GetSource(I[3], targ1);
  {
    Uint live = tb((tmp_packed2>>BEAM_WIDE_SHIFT));
    Uint res;

    HEAVY_SWAPOUT;
    reg[live] = x(SCRATCH_X_REG);
    res = erts_bs_append(c_p, reg, live, targ1, Ib(tmp_packed2&BEAM_WIDE_MASK), tb(tmp_packed3&BEAM_LOOSE_MASK));
    HEAVY_SWAPIN;
    if (is_non_value(res)) {
      /* c_p->freason is already set (to BADARG or SYSTEM_LIMIT). */

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;
    }
    yb((tmp_packed3>>BEAM_LOOSE_SHIFT)) = res;
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

{
  Eterm context;
  OpCase(i_bs_get_binary2_xftstd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_binary2__execute;

  OpCase(i_bs_get_binary2_yftstd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_binary2__execute;

  i_bs_get_binary2__execute:
  {
    Eterm tmp_packed1 = I[2];
    Eterm targ1;
    Eterm dst = db((tmp_packed1>>(2*BEAM_TIGHT_SHIFT)));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    GetSource(I[3], targ1);
    {
      ErlBinMatchBuffer *_mb;
      Eterm _result;
      Uint _size;
      if (is_small(targ1)) {
        Uint uint_size;
        Sint signed_size = signed_val(targ1);
        if (signed_size < 0) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        uint_size = (Uint) signed_size;
        do {
          Uint a = uint_size;
          Uint b = ((tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK)) >> 3);
          Uint res;
#ifdef HAVE_OVERFLOW_CHECK_BUILTINS
          if (__builtin_mul_overflow(a, b, &res)) {
            ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
            I += I[1] + 0;;
            Goto(*I);;
          }
#else
          res = a * b;
          if (res / b != a) {
            ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
            I += I[1] + 0;;
            Goto(*I);;
          }
#endif
          _size = res;
        } while (0);
      } else {
        /*
        * On a 64-bit architecture, the size of any binary
        * that would fit in the memory fits in a small.
        */
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      };
      do {
        Uint need = EXTRACT_SUB_BIN_HEAP_NEED;
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          do {
            //
            // Since a garbage collection is expensive anyway, we can afford
            // to save the instruction counter so that the correct function will
            // be pointed in the crash dump if the garbage collection fails
            // because of insufficient memory.
            //
            SWAPOUT;
            c_p->i = I;
          } while (0);
          reg[tb(tmp_packed1&BEAM_TIGHT_MASK)] = context;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_TIGHT_MASK)+1, FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          context = reg[tb(tmp_packed1&BEAM_TIGHT_MASK)];
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(EXTRACT_SUB_BIN_HEAP_NEED);
      } while (0);
      _mb = ms_matchbuffer(context);
      LIGHT_SWAPOUT;
      _result = erts_bs_get_binary_2(c_p, _size, tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK), _mb);
      LIGHT_SWAPIN;
      HEAP_SPACE_VERIFIED(0);
      if (is_non_value(_result)) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      } else {
        dst_ptr = REG_TARGET_PTR(dst);
        *dst_ptr = _result;
      }
      I += 4;
      ASSERT(VALID_INSTR(*I));
      Goto(*I);
    }
  }

}

{
  Eterm context;
  OpCase(i_bs_get_binary_all2_xfttd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_binary_all2__execute;

  OpCase(i_bs_get_binary_all2_yfttd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_binary_all2__execute;

  i_bs_get_binary_all2__execute:
  {
    Eterm tmp_packed1 = I[2];
    Eterm dst = db((tmp_packed1>>(2*BEAM_TIGHT_SHIFT)));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    ErlBinMatchBuffer *_mb;
    Eterm _result;

    do {
      Uint need = EXTRACT_SUB_BIN_HEAP_NEED;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        do {
          //
          // Since a garbage collection is expensive anyway, we can afford
          // to save the instruction counter so that the correct function will
          // be pointed in the crash dump if the garbage collection fails
          // because of insufficient memory.
          //
          SWAPOUT;
          c_p->i = I;
        } while (0);
        reg[tb(tmp_packed1&BEAM_TIGHT_MASK)] = context;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_TIGHT_MASK)+1, FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        context = reg[tb(tmp_packed1&BEAM_TIGHT_MASK)];
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(EXTRACT_SUB_BIN_HEAP_NEED);
    } while (0);
    _mb = ms_matchbuffer(context);
    if (((_mb->size - _mb->offset) % tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK)) == 0) {
      LIGHT_SWAPOUT;
      _result = erts_bs_get_binary_all_2(c_p, _mb);
      LIGHT_SWAPIN;
      HEAP_SPACE_VERIFIED(0);
      ASSERT(is_value(_result));
      dst_ptr = REG_TARGET_PTR(dst);
      *dst_ptr = _result;
    } else {
      HEAP_SPACE_VERIFIED(0);
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm context;
  OpCase(i_bs_get_binary_imm2_xftWtd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_binary_imm2__execute;

  OpCase(i_bs_get_binary_imm2_yftWtd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_binary_imm2__execute;

  i_bs_get_binary_imm2__execute:
  {
    Eterm tmp_packed1 = I[2];
    Eterm dst = db((tmp_packed1>>(2*BEAM_TIGHT_SHIFT)));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    ErlBinMatchBuffer *_mb;
    Eterm _result;
    do {
      Uint need = EXTRACT_SUB_BIN_HEAP_NEED;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        do {
          //
          // Since a garbage collection is expensive anyway, we can afford
          // to save the instruction counter so that the correct function will
          // be pointed in the crash dump if the garbage collection fails
          // because of insufficient memory.
          //
          SWAPOUT;
          c_p->i = I;
        } while (0);
        reg[tb(tmp_packed1&BEAM_TIGHT_MASK)] = context;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_TIGHT_MASK)+1, FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        context = reg[tb(tmp_packed1&BEAM_TIGHT_MASK)];
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(EXTRACT_SUB_BIN_HEAP_NEED);
    } while (0);
    _mb = ms_matchbuffer(context);
    LIGHT_SWAPOUT;
    _result = erts_bs_get_binary_2(c_p, I[3], tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK), _mb);
    LIGHT_SWAPIN;
    HEAP_SPACE_VERIFIED(0);
    if (is_non_value(_result)) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    } else {
      dst_ptr = REG_TARGET_PTR(dst);
      *dst_ptr = _result;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm context;
  OpCase(i_bs_get_float2_xftstd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_float2__execute;

  OpCase(i_bs_get_float2_yftstd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_float2__execute;

  i_bs_get_float2__execute:
  {
    Eterm tmp_packed1 = I[2];
    Eterm targ1;
    Eterm dst = db((tmp_packed1>>(2*BEAM_TIGHT_SHIFT)));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    GetSource(I[3], targ1);
    {
      ErlBinMatchBuffer *_mb;
      Eterm _result;
      Sint _size;

      if (!is_small(targ1) || (_size = unsigned_val(targ1)) > 64) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      _size *= ((tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK)) >> 3);
      do {
        Uint need = FLOAT_SIZE_OBJECT;
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          do {
            //
            // Since a garbage collection is expensive anyway, we can afford
            // to save the instruction counter so that the correct function will
            // be pointed in the crash dump if the garbage collection fails
            // because of insufficient memory.
            //
            SWAPOUT;
            c_p->i = I;
          } while (0);
          reg[tb(tmp_packed1&BEAM_TIGHT_MASK)] = context;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_TIGHT_MASK)+1, FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          context = reg[tb(tmp_packed1&BEAM_TIGHT_MASK)];
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(FLOAT_SIZE_OBJECT);
      } while (0);
      _mb = ms_matchbuffer(context);
      LIGHT_SWAPOUT;
      _result = erts_bs_get_float_2(c_p, _size, (tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK)), _mb);
      LIGHT_SWAPIN;
      HEAP_SPACE_VERIFIED(0);
      if (is_non_value(_result)) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      } else {
        dst_ptr = REG_TARGET_PTR(dst);
        *dst_ptr = _result;
      }
      I += 4;
      ASSERT(VALID_INSTR(*I));
      Goto(*I);
    }
  }

}

{
  Eterm context;
  OpCase(i_bs_get_integer_16_xfd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_integer_16__execute;

  OpCase(i_bs_get_integer_16_yfd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_integer_16__execute;

  i_bs_get_integer_16__execute:
  {
    Eterm tmp_packed1 = I[1];
    Eterm dst = db((tmp_packed1>>BEAM_WIDE_SHIFT));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    Eterm _result;
    ErlBinMatchBuffer* _mb = ms_matchbuffer(context);

    if (_mb->size - _mb->offset < 16) {
      ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
      I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
      Goto(*I);;
    }
    if (BIT_OFFSET(_mb->offset) != 0) {
      _result = erts_bs_get_integer_2(c_p, 16, 0, _mb);
    } else {
      _result = make_small(get_int16(_mb->base+BYTE_OFFSET(_mb->offset)));
      _mb->offset += 16;
    }
    *dst_ptr = _result;
    I += 2;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm context;
  OpCase(i_bs_get_integer_32_xfd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_integer_32__execute;

  OpCase(i_bs_get_integer_32_yfd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_integer_32__execute;

  i_bs_get_integer_32__execute:
  {
    Eterm tmp_packed1 = I[1];
    Eterm dst = db((tmp_packed1>>BEAM_WIDE_SHIFT));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    Uint32 _integer;
    ErlBinMatchBuffer* _mb = ms_matchbuffer(context);

    if (_mb->size - _mb->offset < 32) {
      ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
      I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
      Goto(*I);;
    }
    if (BIT_OFFSET(_mb->offset) != 0) {
      _integer = erts_bs_get_unaligned_uint32(_mb);
    } else {
      _integer = get_int32(_mb->base + _mb->offset/8);
    }
    _mb->offset += 32;
    *dst_ptr = make_small(_integer);
    I += 2;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm context;
  OpCase(i_bs_get_integer_8_xfd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_integer_8__execute;

  OpCase(i_bs_get_integer_8_yfd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_integer_8__execute;

  i_bs_get_integer_8__execute:
  {
    Eterm tmp_packed1 = I[1];
    Eterm dst = db((tmp_packed1>>BEAM_WIDE_SHIFT));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    Eterm _result;
    ErlBinMatchBuffer* _mb = ms_matchbuffer(context);

    if (_mb->size - _mb->offset < 8) {
      ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
      I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
      Goto(*I);;
    }
    if (BIT_OFFSET(_mb->offset) != 0) {
      _result = erts_bs_get_integer_2(c_p, 8, 0, _mb);
    } else {
      _result = make_small(_mb->base[BYTE_OFFSET(_mb->offset)]);
      _mb->offset += 8;
    }
    *dst_ptr = _result;
    I += 2;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm Ms, Sz;
  OpCase(i_bs_get_integer_imm_xWtftx):
  {
    Eterm tmp_packed1 = BeamExtraData(I[0]);
    Uint wordsneeded;
    Ms = xb(tmp_packed1&BEAM_TIGHT_MASK);
    Sz = I[1];
    wordsneeded = 1+WSIZE(NBYTES(Sz));
    do {
      Uint need = wordsneeded;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        do {
          //
          // Since a garbage collection is expensive anyway, we can afford
          // to save the instruction counter so that the correct function will
          // be pointed in the crash dump if the garbage collection fails
          // because of insufficient memory.
          //
          SWAPOUT;
          c_p->i = I;
        } while (0);
        reg[tb((tmp_packed1>>BEAM_TIGHT_SHIFT))] = Ms;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb((tmp_packed1>>BEAM_TIGHT_SHIFT))+1, FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        Ms = reg[tb((tmp_packed1>>BEAM_TIGHT_SHIFT))];
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(wordsneeded);
    } while (0);
  }
  goto bs_get_integer__execute;

  OpCase(i_bs_get_integer_imm_yWtftx):
  {
    Eterm tmp_packed1 = BeamExtraData(I[0]);
    Uint wordsneeded;
    Ms = yb(tmp_packed1&BEAM_TIGHT_MASK);
    Sz = I[1];
    wordsneeded = 1+WSIZE(NBYTES(Sz));
    do {
      Uint need = wordsneeded;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        do {
          //
          // Since a garbage collection is expensive anyway, we can afford
          // to save the instruction counter so that the correct function will
          // be pointed in the crash dump if the garbage collection fails
          // because of insufficient memory.
          //
          SWAPOUT;
          c_p->i = I;
        } while (0);
        reg[tb((tmp_packed1>>BEAM_TIGHT_SHIFT))] = Ms;
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb((tmp_packed1>>BEAM_TIGHT_SHIFT))+1, FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        Ms = reg[tb((tmp_packed1>>BEAM_TIGHT_SHIFT))];
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(wordsneeded);
    } while (0);
  }
  goto bs_get_integer__execute;

  OpCase(i_bs_get_integer_small_imm_xWftx):
  {
    Ms = xb(BeamExtraData(I[0]));
    Sz = I[1];
  }
  goto bs_get_integer__execute;

  OpCase(i_bs_get_integer_small_imm_yWftx):
  {
    Ms = yb(BeamExtraData(I[0]));
    Sz = I[1];
  }
  goto bs_get_integer__execute;

  bs_get_integer__execute:
  {
    Eterm tmp_packed1 = I[3];
    ErlBinMatchBuffer* mb;
    Eterm result;

    mb = ms_matchbuffer(Ms);
    LIGHT_SWAPOUT;
    result = erts_bs_get_integer_2(c_p, Sz, tb(tmp_packed1&BEAM_LOOSE_MASK), mb);
    LIGHT_SWAPIN;
    HEAP_SPACE_VERIFIED(0);
    if (is_non_value(result)) {
      ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
      I += I[2] + 0;;
      Goto(*I);;
    }
    xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = result;
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm context;
  OpCase(i_bs_get_integer_xfttsd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_integer__execute;

  OpCase(i_bs_get_integer_yfttsd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_integer__execute;

  i_bs_get_integer__execute:
  {
    Eterm tmp_packed1 = I[2];
    Eterm targ1;
    Eterm dst = db((tmp_packed1>>(2*BEAM_TIGHT_SHIFT)));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    GetSource(I[3], targ1);
    {
      Uint flags;
      Uint size;
      ErlBinMatchBuffer* mb;
      Eterm result;

      flags = tb((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK);
      if (is_small(targ1)) {
        Uint uint_size;
        Sint signed_size = signed_val(targ1);
        if (signed_size < 0) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        uint_size = (Uint) signed_size;
        do {
          Uint a = uint_size;
          Uint b = (flags >> 3);
          Uint res;
#ifdef HAVE_OVERFLOW_CHECK_BUILTINS
          if (__builtin_mul_overflow(a, b, &res)) {
            ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
            I += I[1] + 0;;
            Goto(*I);;
          }
#else
          res = a * b;
          if (res / b != a) {
            ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
            I += I[1] + 0;;
            Goto(*I);;
          }
#endif
          size = res;
        } while (0);
      } else {
        /*
        * On a 64-bit architecture, the size of any binary
        * that would fit in the memory fits in a small.
        */
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      };
      if (size >= SMALL_BITS) {
        Uint wordsneeded;
        /* Check bits size before potential gc.
        * We do not want a gc and then realize we don't need
        * the allocated space (i.e. if the op fails).
        *
        * Remember to re-acquire the matchbuffer after gc.
        */

        mb = ms_matchbuffer(context);
        if (mb->size - mb->offset < size) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        wordsneeded = 1+WSIZE(NBYTES((Uint) size));
        do {
          Uint need = wordsneeded;
          if (ERTS_UNLIKELY(E - HTOP < need)) {
            do {
              //
              // Since a garbage collection is expensive anyway, we can afford
              // to save the instruction counter so that the correct function will
              // be pointed in the crash dump if the garbage collection fails
              // because of insufficient memory.
              //
              SWAPOUT;
              c_p->i = I;
            } while (0);
            reg[tb(tmp_packed1&BEAM_TIGHT_MASK)] = context;
            PROCESS_MAIN_CHK_LOCKS(c_p);
            FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_TIGHT_MASK)+1, FCALLS);
            ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
            PROCESS_MAIN_CHK_LOCKS(c_p);
            context = reg[tb(tmp_packed1&BEAM_TIGHT_MASK)];
            SWAPIN;
          }
          HEAP_SPACE_VERIFIED(wordsneeded);
        } while (0);
        dst_ptr = REG_TARGET_PTR(dst);
      }
      mb = ms_matchbuffer(context);
      LIGHT_SWAPOUT;
      result = erts_bs_get_integer_2(c_p, size, flags, mb);
      LIGHT_SWAPIN;
      HEAP_SPACE_VERIFIED(0);
      if (is_non_value(result)) {
        ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
        I += I[1] + 0;;
        Goto(*I);;
      }
      *dst_ptr = result;
      I += 4;
      ASSERT(VALID_INSTR(*I));
      Goto(*I);
    }
  }

}

OpCase(i_bs_get_position_xx):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchBuffer* mb;
  Eterm context;

  context = xb(tmp_packed1&BEAM_TIGHT_MASK);
  ASSERT(header_is_bin_matchstate(*boxed_val(context)));

  mb = ms_matchbuffer(context);
  xb((tmp_packed1>>BEAM_TIGHT_SHIFT)) = make_small(mb->offset);
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_get_position_xy):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchBuffer* mb;
  Eterm context;

  context = xb(tmp_packed1&BEAM_TIGHT_MASK);
  ASSERT(header_is_bin_matchstate(*boxed_val(context)));

  mb = ms_matchbuffer(context);
  yb((tmp_packed1>>BEAM_TIGHT_SHIFT)) = make_small(mb->offset);
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_get_position_yx):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchBuffer* mb;
  Eterm context;

  context = yb(tmp_packed1&BEAM_TIGHT_MASK);
  ASSERT(header_is_bin_matchstate(*boxed_val(context)));

  mb = ms_matchbuffer(context);
  xb((tmp_packed1>>BEAM_TIGHT_SHIFT)) = make_small(mb->offset);
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_get_position_yy):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ErlBinMatchBuffer* mb;
  Eterm context;

  context = yb(tmp_packed1&BEAM_TIGHT_MASK);
  ASSERT(header_is_bin_matchstate(*boxed_val(context)));

  mb = ms_matchbuffer(context);
  yb((tmp_packed1>>BEAM_TIGHT_SHIFT)) = make_small(mb->offset);
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

{
  Eterm context;
  OpCase(i_bs_get_utf16_xftd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_utf16__execute;

  OpCase(i_bs_get_utf16_yftd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_utf16__execute;

  i_bs_get_utf16__execute:
  {
    Eterm tmp_packed1 = I[2];
    Eterm dst = db((tmp_packed1>>BEAM_LOOSE_SHIFT));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    ErlBinMatchBuffer* mb = ms_matchbuffer(context);
    Eterm result = erts_bs_get_utf16(mb, tb(tmp_packed1&BEAM_LOOSE_MASK));

    if (is_non_value(result)) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    }
    dst_ptr = REG_TARGET_PTR(dst);
    *dst_ptr = result;
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm context;
  OpCase(i_bs_get_utf8_xfd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_get_utf8__execute;

  OpCase(i_bs_get_utf8_yfd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_get_utf8__execute;

  i_bs_get_utf8__execute:
  {
    Eterm tmp_packed1 = I[1];
    Eterm dst = db((tmp_packed1>>BEAM_WIDE_SHIFT));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    Eterm result;
    ErlBinMatchBuffer* mb = ms_matchbuffer(context);

    if (mb->size - mb->offset < 8) {
      ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
      I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
      Goto(*I);;
    }
    if (BIT_OFFSET(mb->offset) != 0) {
      result = erts_bs_get_utf8(mb);
    } else {
      byte b = mb->base[BYTE_OFFSET(mb->offset)];
      if (b < 128) {
        result = make_small(b);
        mb->offset += 8;
      } else {
        result = erts_bs_get_utf8(mb);
      }
    }
    if (is_non_value(result)) {
      ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
      I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
      Goto(*I);;
    }
    dst_ptr = REG_TARGET_PTR(dst);
    *dst_ptr = result;
    I += 2;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm BsOp1;
  Eterm BsOp2;
  OpCase(i_bs_init_Wtx):
  {
    BsOp1 = I[1];
    BsOp2 = 0;
  }
  goto bs_init__execute;

  OpCase(i_bs_init_fail_heap_sIjtx):
  {
    Eterm targ1;
    GetSource(I[1], targ1);
    {
      BsOp1 = targ1;
      BsOp2 = Ib(BeamExtraData(I[0]));
    }
  }
  I += 1;
  goto bs_init__verify;

  OpCase(i_bs_init_fail_xjtx):
  {
    BsOp1 = xb(BeamExtraData(I[0]));
    BsOp2 = 0;
  }
  goto bs_init__verify;

  OpCase(i_bs_init_fail_yjtx):
  {
    BsOp1 = yb(BeamExtraData(I[0]));
    BsOp2 = 0;
  }
  goto bs_init__verify;

  OpCase(i_bs_init_heap_WItx):
  {
    BsOp1 = I[1];
    BsOp2 = Ib(BeamExtraData(I[0]));
  }
  goto bs_init__execute;

  bs_init__verify:
  {
    if (is_small(BsOp1)) {
      Sint size = signed_val(BsOp1);
      if (size < 0) {
        c_p->freason = BADARG;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[1])) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      BsOp1 = (Eterm) size;
    } else {
      Uint bytes;

      if (!term_to_Uint(BsOp1, &bytes)) {
        c_p->freason = bytes;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[1])) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        goto find_func_info;;
      }
      if ((bytes >> (8*sizeof(Uint)-3)) != 0) {
        c_p->freason = SYSTEM_LIMIT;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[1])) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      BsOp1 = (Eterm) bytes;
    }
  }
  goto bs_init__execute;

  bs_init__execute:
  {
    Eterm tmp_packed1 = I[2];
    BeamInstr next_pf = BeamCodeAddr(I[3]);
    if (BsOp1 <= ERL_ONHEAP_BIN_LIMIT) {
      ErlHeapBin* hb;
      Uint bin_need;

      bin_need = heap_bin_size(BsOp1);
      erts_bin_offset = 0;
      erts_writable_bin = 0;
      do {
        Uint need = bin_need+BsOp2+ERL_SUB_BIN_SIZE + 0;
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          do {
            //
            // Since a garbage collection is expensive anyway, we can afford
            // to save the instruction counter so that the correct function will
            // be pointed in the crash dump if the garbage collection fails
            // because of insufficient memory.
            //
            SWAPOUT;
            c_p->i = I;
          } while (0);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_LOOSE_MASK), FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(bin_need+BsOp2+ERL_SUB_BIN_SIZE);
      } while (0);
      hb = (ErlHeapBin *) HTOP;
      HTOP += bin_need;
      hb->thing_word = header_heap_bin(BsOp1);
      hb->size = BsOp1;
      erts_current_bin = (byte *) hb->data;
      xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = make_binary(hb);
    } else {
      Binary* bptr;
      ProcBin* pb;

      erts_bin_offset = 0;
      erts_writable_bin = 0;
      do {
        Uint need = BsOp2 + PROC_BIN_SIZE + ERL_SUB_BIN_SIZE;
        if (E - HTOP < need || MSO(c_p).overhead + BsOp1 / sizeof(Eterm) >= BIN_VHEAP_SZ(c_p)) {
          do {
            //
            // Since a garbage collection is expensive anyway, we can afford
            // to save the instruction counter so that the correct function will
            // be pointed in the crash dump if the garbage collection fails
            // because of insufficient memory.
            //
            SWAPOUT;
            c_p->i = I;
          } while (0);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_LOOSE_MASK), FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(need);
      } while (0);

      /*
      * Allocate the binary struct itself.
      */
      bptr = erts_bin_nrml_alloc(BsOp1);
      erts_current_bin = (byte *) bptr->orig_bytes;

      /*
      * Now allocate the ProcBin on the heap.
      */
      pb = (ProcBin *) HTOP;
      HTOP += PROC_BIN_SIZE;
      pb->thing_word = HEADER_PROC_BIN;
      pb->size = BsOp1;
      pb->next = MSO(c_p).first;
      MSO(c_p).first = (struct erl_off_heap_header*) pb;
      pb->val = bptr;
      pb->bytes = (byte*) bptr->orig_bytes;
      pb->flags = 0;

      OH_OVERHEAD(&(MSO(c_p)), BsOp1 / sizeof(Eterm));

      xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = make_binary(pb);
    }
    I += 3;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }

}

{
  Eterm num_bits_term;
  Uint num_bits;
  Uint alloc;
  OpCase(i_bs_init_bits_Wtx):
  {
    num_bits = I[1];
    alloc = 0;
  }
  goto bs_init_bits__execute;

  OpCase(i_bs_init_bits_fail_heap_sIjtx):
  {
    Eterm targ1;
    GetSource(I[1], targ1);
    {
      num_bits_term = targ1;
      alloc = Ib(BeamExtraData(I[0]));
    }
  }
  I += 1;
  goto bs_init_bits__verify;

  OpCase(i_bs_init_bits_fail_xjtx):
  {
    num_bits_term = xb(BeamExtraData(I[0]));
    alloc = 0;
  }
  goto bs_init_bits__verify;

  OpCase(i_bs_init_bits_fail_yjtx):
  {
    num_bits_term = yb(BeamExtraData(I[0]));
    alloc = 0;
  }
  goto bs_init_bits__verify;

  OpCase(i_bs_init_bits_heap_WItx):
  {
    num_bits = I[1];
    alloc = Ib(BeamExtraData(I[0]));
  }
  goto bs_init_bits__execute;

  bs_init_bits__verify:
  {
    if (is_small(num_bits_term)) {
      Sint size = signed_val(num_bits_term);
      if (size < 0) {
        c_p->freason = BADARG;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[1])) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      num_bits = (Uint) size;
    } else {
      Uint bits;

      if (!term_to_Uint(num_bits_term, &bits)) {
        c_p->freason = bits;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(I[1])) {
          ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
          I += I[1] + 0;;
          Goto(*I);;
        }
        goto find_func_info;;
      }
      num_bits = (Uint) bits;
    }
  }
  goto bs_init_bits__execute;

  bs_init_bits__execute:
  {
    Eterm tmp_packed1 = I[2];
    BeamInstr next_pf = BeamCodeAddr(I[3]);
    Eterm new_binary;
    Uint num_bytes = ((Uint64)num_bits+(Uint64)7) >> 3;

    if (num_bits & 7) {
      alloc += ERL_SUB_BIN_SIZE;
    }
    if (num_bytes <= ERL_ONHEAP_BIN_LIMIT) {
      alloc += heap_bin_size(num_bytes);
    } else {
      alloc += PROC_BIN_SIZE;
    }
    do {
      Uint need = alloc + 0;
      if (ERTS_UNLIKELY(E - HTOP < need)) {
        do {
          //
          // Since a garbage collection is expensive anyway, we can afford
          // to save the instruction counter so that the correct function will
          // be pointed in the crash dump if the garbage collection fails
          // because of insufficient memory.
          //
          SWAPOUT;
          c_p->i = I;
        } while (0);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, tb(tmp_packed1&BEAM_LOOSE_MASK), FCALLS);
        ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
        PROCESS_MAIN_CHK_LOCKS(c_p);
        SWAPIN;
      }
      HEAP_SPACE_VERIFIED(alloc);
    } while (0);;

    /* num_bits = Number of bits to build
    * num_bytes = Number of bytes to allocate in the binary
    * alloc = Total number of words to allocate on heap
    * Operands: NotUsed NotUsed Dst
    */
    if (num_bytes <= ERL_ONHEAP_BIN_LIMIT) {
      ErlHeapBin* hb;

      erts_bin_offset = 0;
      erts_writable_bin = 0;
      hb = (ErlHeapBin *) HTOP;
      HTOP += heap_bin_size(num_bytes);
      hb->thing_word = header_heap_bin(num_bytes);
      hb->size = num_bytes;
      erts_current_bin = (byte *) hb->data;
      new_binary = make_binary(hb);

      do_bits_sub_bin:
      if (num_bits & 7) {
        ErlSubBin* sb;

        sb = (ErlSubBin *) HTOP;
        HTOP += ERL_SUB_BIN_SIZE;
        sb->thing_word = HEADER_SUB_BIN;
        sb->size = num_bytes - 1;
        sb->bitsize = num_bits & 7;
        sb->offs = 0;
        sb->bitoffs = 0;
        sb->is_writable = 0;
        sb->orig = new_binary;
        new_binary = make_binary(sb);
      }
      HEAP_SPACE_VERIFIED(0);
      xb((tmp_packed1>>BEAM_LOOSE_SHIFT)) = new_binary;
    } else {
      Binary* bptr;
      ProcBin* pb;

      erts_bin_offset = 0;
      erts_writable_bin = 0;

      /*
      * Allocate the binary struct itself.
      */
      bptr = erts_bin_nrml_alloc(num_bytes);
      erts_current_bin = (byte *) bptr->orig_bytes;

      /*
      * Now allocate the ProcBin on the heap.
      */
      pb = (ProcBin *) HTOP;
      HTOP += PROC_BIN_SIZE;
      pb->thing_word = HEADER_PROC_BIN;
      pb->size = num_bytes;
      pb->next = MSO(c_p).first;
      MSO(c_p).first = (struct erl_off_heap_header*) pb;
      pb->val = bptr;
      pb->bytes = (byte*) bptr->orig_bytes;
      pb->flags = 0;
      OH_OVERHEAD(&(MSO(c_p)), pb->size / sizeof(Eterm));
      new_binary = make_binary(pb);
      goto do_bits_sub_bin;
    }
    I += 3;
    ASSERT(VALID_INSTR(next_pf));
    GotoPF(next_pf);
  }

}

OpCase(i_bs_match_string_xfWW):
{
  byte* bytes = (byte *) I[3];
  Uint bits = I[2];
  ErlBinMatchBuffer* mb;
  Uint offs;

  mb = ms_matchbuffer(xb(BeamExtraData(I[0])));
  if (mb->size - mb->offset < bits) {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  offs = mb->offset & 7;
  if (offs == 0 && (bits & 7) == 0) {
    if (sys_memcmp(bytes, mb->base+(mb->offset>>3), bits>>3)) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    }
  } else if (erts_cmp_bits(bytes, 0, mb->base+(mb->offset>>3), mb->offset & 7, bits)) {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  mb->offset += bits;
  I += 4;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_match_string_yfWW):
{
  byte* bytes = (byte *) I[3];
  Uint bits = I[2];
  ErlBinMatchBuffer* mb;
  Uint offs;

  mb = ms_matchbuffer(yb(BeamExtraData(I[0])));
  if (mb->size - mb->offset < bits) {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  offs = mb->offset & 7;
  if (offs == 0 && (bits & 7) == 0) {
    if (sys_memcmp(bytes, mb->base+(mb->offset>>3), bits>>3)) {
      ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
      I += I[1] + 0;;
      Goto(*I);;
    }
  } else if (erts_cmp_bits(bytes, 0, mb->base+(mb->offset>>3), mb->offset & 7, bits)) {
    ASSERT(VALID_INSTR(*(I + (I[1]) + 0)));
    I += I[1] + 0;;
    Goto(*I);;
  }
  mb->offset += bits;
  I += 4;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_private_append_jtsSx):
{
  Eterm tmp_packed2 = I[1];
  Eterm targ1;
  GetSource(I[2], targ1);
  {
    Eterm res;

    res = erts_bs_private_append(c_p, Sb((tmp_packed2>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK), targ1, tb(tmp_packed2&BEAM_TIGHT_MASK));
    if (is_non_value(res)) {
      /* c_p->freason is already set (to BADARG or SYSTEM_LIMIT). */

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;
    }
    xb((tmp_packed2>>(2*BEAM_TIGHT_SHIFT))) = res;
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_bs_put_utf8_jS):
{
  if (!erts_bs_put_utf8(ERL_BITS_ARGS_1(Sb(I[1])))) {
    c_p->freason = BADARG;

    /*
    * In a correctly working program, we expect failures in
    * guards to be more likely than failures in bodies.
    */

    if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
      ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
      I += jb(BeamExtraData(I[0])) + 0;;
      Goto(*I);;
    }
    goto find_func_info;;;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

{
  Eterm context, bits;
  OpCase(i_bs_skip_bits2_xxft):
  {
    Eterm tmp_packed1 = BeamExtraData(I[0]);
    context = xb(tmp_packed1&BEAM_TIGHT_MASK);
    bits = xb((tmp_packed1>>BEAM_TIGHT_SHIFT));
  }
  goto i_bs_skip_bits2__execute;

  OpCase(i_bs_skip_bits2_xyft):
  {
    Eterm tmp_packed1 = BeamExtraData(I[0]);
    context = xb(tmp_packed1&BEAM_TIGHT_MASK);
    bits = yb((tmp_packed1>>BEAM_TIGHT_SHIFT));
  }
  goto i_bs_skip_bits2__execute;

  OpCase(i_bs_skip_bits2_yxft):
  {
    Eterm tmp_packed1 = BeamExtraData(I[0]);
    context = yb(tmp_packed1&BEAM_TIGHT_MASK);
    bits = xb((tmp_packed1>>BEAM_TIGHT_SHIFT));
  }
  goto i_bs_skip_bits2__execute;

  OpCase(i_bs_skip_bits2_yyft):
  {
    Eterm tmp_packed1 = BeamExtraData(I[0]);
    context = yb(tmp_packed1&BEAM_TIGHT_MASK);
    bits = yb((tmp_packed1>>BEAM_TIGHT_SHIFT));
  }
  goto i_bs_skip_bits2__execute;

  i_bs_skip_bits2__execute:
  {
    Eterm tmp_packed1 = I[1];
    ErlBinMatchBuffer *_mb;
    size_t new_offset;
    Uint _size;

    _mb = ms_matchbuffer(context);
    if (is_small(bits)) {
      Uint uint_size;
      Sint signed_size = signed_val(bits);
      if (signed_size < 0) {
        ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      uint_size = (Uint) signed_size;
      do {
        Uint a = uint_size;
        Uint b = tb((tmp_packed1>>BEAM_WIDE_SHIFT));
        Uint res;
#ifdef HAVE_OVERFLOW_CHECK_BUILTINS
        if (__builtin_mul_overflow(a, b, &res)) {
          ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
          I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
          Goto(*I);;
        }
#else
        res = a * b;
        if (res / b != a) {
          ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
          I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
          Goto(*I);;
        }
#endif
        _size = res;
      } while (0);
    } else {
      /*
      * On a 64-bit architecture, the size of any binary
      * that would fit in the memory fits in a small.
      */
      ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
      I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
      Goto(*I);;
    };
    new_offset = _mb->offset + _size;
    if (new_offset <= _mb->size) {
      _mb->offset = new_offset;
    } else {
      ASSERT(VALID_INSTR(*(I + (fb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
      I += fb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
      Goto(*I);;
    }
    I += 2;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

OpCase(i_bs_skip_bits_imm2_fxW):
{
  ErlBinMatchBuffer *_mb;
  size_t new_offset;
  _mb = ms_matchbuffer(xb(I[1]));
  new_offset = _mb->offset + (I[2]);
  if (new_offset <= _mb->size) {
    _mb->offset = new_offset;
  } else {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_skip_bits_imm2_fyW):
{
  ErlBinMatchBuffer *_mb;
  size_t new_offset;
  _mb = ms_matchbuffer(yb(I[1]));
  new_offset = _mb->offset + (I[2]);
  if (new_offset <= _mb->size) {
    _mb->offset = new_offset;
  } else {
    ASSERT(VALID_INSTR(*(I + (fb(BeamExtraData(I[0]))) + 0)));
    I += fb(BeamExtraData(I[0])) + 0;;
    Goto(*I);;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

{
  Eterm context;
  OpCase(i_bs_start_match3_gp_xtfdx):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_start_match3_gp__execute;

  OpCase(i_bs_start_match3_gp_ytfdx):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_start_match3_gp__execute;

  i_bs_start_match3_gp__execute:
  {
    Eterm tmp_packed1 = I[1];
    Eterm dst = db((tmp_packed1>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK);
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    Eterm header;
    Uint position, live;

    live = tb(tmp_packed1&BEAM_TIGHT_MASK);

    if (!is_boxed(context)) {
      ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
      I += I[2] + 0;;
      Goto(*I);;
    }

    header = *boxed_val(context);

    if (header_is_bin_matchstate(header)) {
      ErlBinMatchBuffer *mb;

      ASSERT(HEADER_NUM_SLOTS(header) == 0);

      mb = ms_matchbuffer(context);
      position = mb->offset;

      *dst_ptr = context;
    } else if (is_binary_header(header)) {
      ErlBinMatchState *ms;

      do {
        Uint need = ERL_BIN_MATCHSTATE_SIZE(0);
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          do {
            //
            // Since a garbage collection is expensive anyway, we can afford
            // to save the instruction counter so that the correct function will
            // be pointed in the crash dump if the garbage collection fails
            // because of insufficient memory.
            //
            SWAPOUT;
            c_p->i = I;
          } while (0);
          reg[live] = context;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, live+1, FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          context = reg[live];
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(ERL_BIN_MATCHSTATE_SIZE(0));
      } while (0);
      HEAP_TOP(c_p) = HTOP;
#ifdef DEBUG
      c_p->stop = E;	/* Needed for checking in HeapOnlyAlloc(). */
#endif
      ms = erts_bs_start_match_3(c_p, context);
      HTOP = HEAP_TOP(c_p);
      HEAP_SPACE_VERIFIED(0);

      dst_ptr = REG_TARGET_PTR(dst);
      *dst_ptr = make_matchstate(ms);
      position = ms->mb.offset;
    } else {
      ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
      I += I[2] + 0;;
      Goto(*I);;
    }

    ASSERT(IS_USMALL(0, position));
    xb((tmp_packed1>>(2*BEAM_TIGHT_SHIFT))) = make_small(position);
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

{
  Eterm context;
  OpCase(i_bs_start_match3_xtfd):
  {
    context = xb(BeamExtraData(I[0]));
  }
  goto i_bs_start_match3__execute;

  OpCase(i_bs_start_match3_ytfd):
  {
    context = yb(BeamExtraData(I[0]));
  }
  goto i_bs_start_match3__execute;

  i_bs_start_match3__execute:
  {
    Eterm tmp_packed1 = I[1];
    Eterm dst = db((tmp_packed1>>BEAM_LOOSE_SHIFT));
    Eterm* dst_ptr = REG_TARGET_PTR(dst);
    Eterm header;
    Uint live;

    live = tb(tmp_packed1&BEAM_LOOSE_MASK);

    if (!is_boxed(context)) {
      ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
      I += I[2] + 0;;
      Goto(*I);;
    }

    header = *boxed_val(context);

    if (header_is_bin_matchstate(header)) {
      ASSERT(HEADER_NUM_SLOTS(header) == 0);
      *dst_ptr = context;
    } else if (is_binary_header(header)) {
      ErlBinMatchState *ms;

      do {
        Uint need = ERL_BIN_MATCHSTATE_SIZE(0);
        if (ERTS_UNLIKELY(E - HTOP < need)) {
          do {
            //
            // Since a garbage collection is expensive anyway, we can afford
            // to save the instruction counter so that the correct function will
            // be pointed in the crash dump if the garbage collection fails
            // because of insufficient memory.
            //
            SWAPOUT;
            c_p->i = I;
          } while (0);
          reg[live] = context;
          PROCESS_MAIN_CHK_LOCKS(c_p);
          FCALLS -= erts_garbage_collect_nobump(c_p, need, reg, live+1, FCALLS);
          ERTS_VERIFY_UNUSED_TEMP_ALLOC(c_p);
          PROCESS_MAIN_CHK_LOCKS(c_p);
          context = reg[live];
          SWAPIN;
        }
        HEAP_SPACE_VERIFIED(ERL_BIN_MATCHSTATE_SIZE(0));
      } while (0);
      HEAP_TOP(c_p) = HTOP;
#ifdef DEBUG
      c_p->stop = E;	/* Needed for checking in HeapOnlyAlloc(). */
#endif
      ms = erts_bs_start_match_3(c_p, context);
      HTOP = HEAP_TOP(c_p);
      HEAP_SPACE_VERIFIED(0);

      dst_ptr = REG_TARGET_PTR(dst);
      *dst_ptr = make_matchstate(ms);
    } else {
      ASSERT(VALID_INSTR(*(I + (I[2]) + 0)));
      I += I[2] + 0;;
      Goto(*I);;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

OpCase(i_bs_utf16_size_Sx):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  Eterm arg = Sb(tmp_packed1&BEAM_TIGHT_MASK);
  Eterm result = make_small(2);

  /*
  * Calculate the number of bytes needed to encode the source
  * operarand to UTF-16. If the source operand is invalid (e.g. wrong
  * type or range) we return a nonsense integer result (2 or 4). We
  * can get away with that because we KNOW that bs_put_utf16 will do
  * full error checking.
  */

  if (arg >= make_small(0x10000UL)) {
    result = make_small(4);
  }
  xb((tmp_packed1>>BEAM_TIGHT_SHIFT)) = result;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_utf8_size_Sx):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  Eterm arg = Sb(tmp_packed1&BEAM_TIGHT_MASK);
  Eterm result;

  /*
  * Calculate the number of bytes needed to encode the source
  * operand to UTF-8. If the source operand is invalid (e.g. wrong
  * type or range) we return a nonsense integer result (0 or 4). We
  * can get away with that because we KNOW that bs_put_utf8 will do
  * full error checking.
  */

  if (arg < make_small(0x80UL)) {
    result = make_small(1);
  } else if (arg < make_small(0x800UL)) {
    result = make_small(2);
  } else if (arg < make_small(0x10000UL)) {
    result = make_small(3);
  } else {
    result = make_small(4);
  }
  xb((tmp_packed1>>BEAM_TIGHT_SHIFT)) = result;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_bs_validate_unicode_jS):
{
  Eterm val = Sb(I[1]);

  /*
  * There is no need to untag the integer, but it IS necessary
  * to make sure it is small (if the term is a bignum, it could
  * slip through the test, and there is no further test that
  * would catch it, since bit syntax construction silently masks
  * too big numbers).
  */
  if (is_not_small(val) || val > make_small(0x10FFFFUL) ||
  (make_small(0xD800UL) <= val && val <= make_small(0xDFFFUL))) {
    c_p->freason = BADARG;

    /*
    * In a correctly working program, we expect failures in
    * guards to be more likely than failures in bodies.
    */

    if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
      ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
      I += jb(BeamExtraData(I[0])) + 0;;
      Goto(*I);;
    }
    goto find_func_info;;;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_bs_validate_unicode_retract_jsS):
{
  Eterm targ1;
  GetSource(I[1], targ1);
  {
    /*
    * There is no need to untag the integer, but it IS necessary
    * to make sure it is small (a bignum pointer could fall in
    * the valid range).
    */

    Eterm i = targ1;
    if (is_not_small(i) || i > make_small(0x10FFFFUL) ||
    (make_small(0xD800UL) <= i && i <= make_small(0xDFFFUL))) {
      Eterm ms = Sb(I[2]);		/* Match context */
      ErlBinMatchBuffer* mb;

      /* Invalid value. Retract the position in the binary. */
      mb = ms_matchbuffer(ms);
      mb->offset -= 32;
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_fadd_lll):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  l((tmp_packed1>>(2*BEAM_TIGHTEST_SHIFT))) = l(tmp_packed1&BEAM_TIGHTEST_MASK) + l((tmp_packed1>>BEAM_TIGHTEST_SHIFT)&BEAM_TIGHTEST_MASK);
  ERTS_NO_FPE_ERROR(c_p, l((tmp_packed1>>(2*BEAM_TIGHTEST_SHIFT))), c_p->freason = BADARITH;
  goto find_func_info;);;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_fdiv_lll):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  l((tmp_packed1>>(2*BEAM_TIGHTEST_SHIFT))) = l(tmp_packed1&BEAM_TIGHTEST_MASK) / l((tmp_packed1>>BEAM_TIGHTEST_SHIFT)&BEAM_TIGHTEST_MASK);
  ERTS_NO_FPE_ERROR(c_p, l((tmp_packed1>>(2*BEAM_TIGHTEST_SHIFT))), c_p->freason = BADARITH;
  goto find_func_info;);;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_fmul_lll):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  l((tmp_packed1>>(2*BEAM_TIGHTEST_SHIFT))) = l(tmp_packed1&BEAM_TIGHTEST_MASK) * l((tmp_packed1>>BEAM_TIGHTEST_SHIFT)&BEAM_TIGHTEST_MASK);
  ERTS_NO_FPE_ERROR(c_p, l((tmp_packed1>>(2*BEAM_TIGHTEST_SHIFT))), c_p->freason = BADARITH;
  goto find_func_info;);;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_fnegate_ll):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  lb((tmp_packed1>>BEAM_TIGHT_SHIFT)) = -lb(tmp_packed1&BEAM_TIGHT_MASK);
  ERTS_NO_FPE_ERROR(c_p, lb((tmp_packed1>>BEAM_TIGHT_SHIFT)), c_p->freason = BADARITH;
  goto find_func_info;);
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

OpCase(i_fsub_lll):
{
  Eterm tmp_packed1 = BeamExtraData(I[0]);
  BeamInstr next_pf = BeamCodeAddr(I[1]);
  ERTS_NO_FPE_CHECK_INIT(c_p);
  l((tmp_packed1>>(2*BEAM_TIGHTEST_SHIFT))) = l(tmp_packed1&BEAM_TIGHTEST_MASK) - l((tmp_packed1>>BEAM_TIGHTEST_SHIFT)&BEAM_TIGHTEST_MASK);
  ERTS_NO_FPE_ERROR(c_p, l((tmp_packed1>>(2*BEAM_TIGHTEST_SHIFT))), c_p->freason = BADARITH;
  goto find_func_info;);;
  I += 1;
  ASSERT(VALID_INSTR(next_pf));
  GotoPF(next_pf);
}

{
  Eterm src;
  OpCase(i_new_bs_put_binary_all_xjt):
  {
    src = xb(BeamExtraData(I[0]));
  }
  goto i_new_bs_put_binary_all__execute;

  OpCase(i_new_bs_put_binary_all_yjt):
  {
    src = yb(BeamExtraData(I[0]));
  }
  goto i_new_bs_put_binary_all__execute;

  i_new_bs_put_binary_all__execute:
  {
    Eterm tmp_packed1 = I[1];
    if (!erts_new_bs_put_binary_all(ERL_BITS_ARGS_2(src, (tb((tmp_packed1>>BEAM_WIDE_SHIFT)))))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 2;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

OpCase(i_new_bs_put_binary_imm_jWS):
{
  if (!erts_new_bs_put_binary(ERL_BITS_ARGS_2((Sb(I[2])), (I[1])))) {
    c_p->freason = BADARG;

    /*
    * In a correctly working program, we expect failures in
    * guards to be more likely than failures in bodies.
    */

    if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
      ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
      I += jb(BeamExtraData(I[0])) + 0;;
      Goto(*I);;
    }
    goto find_func_info;;;
  }
  I += 3;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_new_bs_put_binary_jStS):
{
  Eterm tmp_packed2 = I[1];
  Eterm sz = Sb(tmp_packed2&BEAM_TIGHT_MASK);
  Sint _size;
  if (is_small(sz)) {
    Uint uint_size;
    Sint signed_size = signed_val(sz);
    if (signed_size < 0) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    uint_size = (Uint) signed_size;
    _size = uint_size * ((tb((tmp_packed2>>BEAM_TIGHT_SHIFT)&BEAM_TIGHT_MASK)) >> 3);
  } else {
    /*
    * On a 64-bit architecture, the size of any binary
    * that would fit in the memory fits in a small.
    */
    c_p->freason = BADARG;

    /*
    * In a correctly working program, we expect failures in
    * guards to be more likely than failures in bodies.
    */

    if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
      ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
      I += jb(BeamExtraData(I[0])) + 0;;
      Goto(*I);;
    }
    goto find_func_info;;;
  };
  if (!erts_new_bs_put_binary(ERL_BITS_ARGS_2((Sb((tmp_packed2>>(2*BEAM_TIGHT_SHIFT)))), _size))) {
    c_p->freason = BADARG;

    /*
    * In a correctly working program, we expect failures in
    * guards to be more likely than failures in bodies.
    */

    if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
      ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
      I += jb(BeamExtraData(I[0])) + 0;;
      Goto(*I);;
    }
    goto find_func_info;;;
  }
  I += 2;
  ASSERT(VALID_INSTR(*I));
  Goto(*I);
}

OpCase(i_new_bs_put_float_imm_jWts):
{
  Eterm targ1;
  GetSource(I[3], targ1);
  {
    if (!erts_new_bs_put_float(c_p, (targ1), (I[1]), (I[2]))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 4;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

OpCase(i_new_bs_put_float_jSts):
{
  Eterm tmp_packed2 = I[1];
  Eterm targ1;
  GetSource(I[2], targ1);
  {
    Eterm sz = Sb(tmp_packed2&BEAM_LOOSE_MASK);
    Eterm flags = tb((tmp_packed2>>BEAM_LOOSE_SHIFT));
    Sint _size;
    if (is_small(sz)) {
      Uint uint_size;
      Sint signed_size = signed_val(sz);
      if (signed_size < 0) {
        c_p->freason = BADARG;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
          ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
          I += jb(BeamExtraData(I[0])) + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      uint_size = (Uint) signed_size;
      _size = uint_size * (flags >> 3);
    } else {
      /*
      * On a 64-bit architecture, the size of any binary
      * that would fit in the memory fits in a small.
      */
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    };
    if (!erts_new_bs_put_float(c_p, (targ1), _size, flags)) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

{
  Eterm src;
  OpCase(i_new_bs_put_integer_imm_cjWt):
  {
    src = I[1];
  }
  I += 1;
  goto i_new_bs_put_integer_imm__execute;

  OpCase(i_new_bs_put_integer_imm_xjWt):
  {
    src = xb(BeamExtraData(I[0]));
  }
  goto i_new_bs_put_integer_imm__execute;

  OpCase(i_new_bs_put_integer_imm_yjWt):
  {
    src = yb(BeamExtraData(I[0]));
  }
  goto i_new_bs_put_integer_imm__execute;

  i_new_bs_put_integer_imm__execute:
  {
    Eterm tmp_packed1 = I[1];
    if (!erts_new_bs_put_integer(ERL_BITS_ARGS_3(src, (I[2]), (tb((tmp_packed1>>BEAM_WIDE_SHIFT)))))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(tmp_packed1&BEAM_WIDE_MASK))) {
        ASSERT(VALID_INSTR(*(I + (jb(tmp_packed1&BEAM_WIDE_MASK)) + 0)));
        I += jb(tmp_packed1&BEAM_WIDE_MASK) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }

}

OpCase(i_new_bs_put_integer_jSts):
{
  Eterm tmp_packed2 = I[1];
  Eterm targ1;
  GetSource(I[2], targ1);
  {
    Eterm sz = Sb(tmp_packed2&BEAM_LOOSE_MASK);
    Eterm flags = tb((tmp_packed2>>BEAM_LOOSE_SHIFT));
    Sint _size;
    if (is_small(sz)) {
      Uint uint_size;
      Sint signed_size = signed_val(sz);
      if (signed_size < 0) {
        c_p->freason = BADARG;

        /*
        * In a correctly working program, we expect failures in
        * guards to be more likely than failures in bodies.
        */

        if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
          ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
          I += jb(BeamExtraData(I[0])) + 0;;
          Goto(*I);;
        }
        goto find_func_info;;;
      }
      uint_size = (Uint) signed_size;
      _size = uint_size * (flags >> 3);
    } else {
      /*
      * On a 64-bit architecture, the size of any binary
      * that would fit in the memory fits in a small.
      */
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    };
    if (!erts_new_bs_put_integer(ERL_BITS_ARGS_3((targ1), _size, flags))) {
      c_p->freason = BADARG;

      /*
      * In a correctly working program, we expect failures in
      * guards to be more likely than failures in bodies.
      */

      if (ERTS_LIKELY(jb(BeamExtraData(I[0])))) {
        ASSERT(VALID_INSTR(*(I + (jb(BeamExtraData(I[0]))) + 0)));
        I += jb(BeamExtraData(I[0])) + 0;;
        Goto(*I);;
      }
      goto find_func_info;;;
    }
    I += 3;
    ASSERT(VALID_INSTR(*I));
    Goto(*I);
  }
}

